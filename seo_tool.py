import json
import datetime

# C·∫§U H√åNH C∆† B·∫¢N
DOMAIN = "https://vpptinh.com"
INPUT_FILE = "products.json"  # T√™n file d·ªØ li·ªáu s·∫£n ph·∫©m c·ªßa b·∫°n
OUTPUT_SITEMAP = "sitemap.xml"
OUTPUT_ROBOTS = "robots.txt"
OUTPUT_SCHEMA = "schema_snippet.html" # File n√†y ch·ª©a code ƒë·ªÉ b·∫°n nh√©t v√†o index.html

def generate_seo_files():
    try:
        # 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ file products.json
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            products = json.load(f)
            print(f"üì¶ ƒê√£ t√¨m th·∫•y {len(products)} s·∫£n ph·∫©m.")
    except FileNotFoundError:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file {INPUT_FILE}. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y tool c√†o d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # --- PH·∫¶N 1: T·∫†O SITEMAP.XML ---
    print("Dang tao sitemap...")
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'

    # 1.1 Th√™m trang ch·ªß
    sitemap_content += '  <url>\n'
    sitemap_content += f'    <loc>{DOMAIN}/</loc>\n'
    sitemap_content += f'    <lastmod>{datetime.date.today()}</lastmod>\n'
    sitemap_content += '    <priority>1.0</priority>\n'
    sitemap_content += '  </url>\n'

    # 1.2 N·∫øu web b·∫°n c√≥ trang chi ti·∫øt (vd: detail.html?id=...), h√£y b·ªè comment d√≤ng d∆∞·ªõi
    # for p in products:
    #     link = f"{DOMAIN}/san-pham/{p.get('itemid')}" # S·ª≠a l·∫°i theo c·∫•u tr√∫c link c·ªßa b·∫°n
    #     sitemap_content += f'  <url><loc>{link}</loc><priority>0.8</priority></url>\n'

    sitemap_content += '</urlset>'
    
    with open(OUTPUT_SITEMAP, 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    print(f"‚úÖ ƒê√£ t·∫°o: {OUTPUT_SITEMAP}")

    # --- PH·∫¶N 2: T·∫†O SCHEMA JSON-LD (Hi·ªán gi√° tr√™n Google) ---
    print("Dang tao Schema Markup...")
    
    # T·∫°o danh s√°ch s·∫£n ph·∫©m theo chu·∫©n Google
    schema_items = []
    for p in products:
        # L∆∞u √Ω: S·ª≠a c√°c key ('name', 'price', 'image') kh·ªõp v·ªõi file json c·ªßa b·∫°n
        item = {
            "@context": "https://schema.org/",
            "@type": "Product",
            "name": p.get('name', 'S·∫£n ph·∫©m VPP T·ªãnh'),
            "image": [p.get('image', '')],
            "description": "S·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng cao t·ª´ VPP T·ªãnh.",
            "sku": str(p.get('itemid', '')),
            "offers": {
                "@type": "Offer",
                "url": DOMAIN, # Ho·∫∑c link chi ti·∫øt s·∫£n ph·∫©m
                "priceCurrency": "VND",
                "price": str(p.get('price', 0)).replace(".","").replace("‚Ç´",""), # L√†m s·∫°ch gi√°
                "availability": "https://schema.org/InStock",
                "itemCondition": "https://schema.org/NewCondition"
            }
        }
        schema_items.append(item)

    # Xu·∫•t ra file HTML nh·ªè ƒë·ªÉ b·∫°n include v√†o
    schema_html = '<script type="application/ld+json">\n'
    schema_html += json.dumps(schema_items, ensure_ascii=False, indent=2)
    schema_html += '\n</script>'

    with open(OUTPUT_SCHEMA, 'w', encoding='utf-8') as f:
        f.write(schema_html)
    print(f"‚úÖ ƒê√£ t·∫°o: {OUTPUT_SCHEMA} (H√£y copy n·ªôi dung file n√†y v√†o th·∫ª <head> c·ªßa index.html)")

    # --- PH·∫¶N 3: T·∫†O ROBOTS.TXT ---
    robots_content = f"User-agent: *\nAllow: /\nSitemap: {DOMAIN}/sitemap.xml"
    with open(OUTPUT_ROBOTS, 'w', encoding='utf-8') as f:
        f.write(robots_content)
    print(f"‚úÖ ƒê√£ t·∫°o: {OUTPUT_ROBOTS}")

if __name__ == "__main__":
    generate_seo_files()